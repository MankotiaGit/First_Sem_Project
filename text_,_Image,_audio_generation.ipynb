{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MankotiaGit/First_Sem_Project/blob/main/text_%2C_Image%2C_audio_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is a prompt\n",
        "A prompt is a natural language request submitted to a language model to receive a response back. Prompts can contain questions, instructions, contextual information, examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more."
      ],
      "metadata": {
        "id": "S1bXrR1d0BSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "FhHhLwiwPoeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyAq9iAsOnsmcLfpiBHWjRyV34LHKboUWZ8\")\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "response = model.generate_content(\"Write a story about a magic backpack.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "e1LcdVAsP-Hs",
        "outputId": "321acccc-2983-43b9-bf21-7668c1304769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elara found the backpack nestled amongst the dusty relics in her grandmother’s attic. It wasn't particularly beautiful – a worn, olive-green canvas, smelling faintly of woodsmoke and something indefinably ancient.  But something about its worn leather straps and tarnished brass buckles drew her in.  She slung it over her shoulder, and a shiver, not of cold, but of anticipation, ran down her spine.\n",
            "\n",
            "That night, Elara needed a pencil. Reaching into the backpack, expecting the usual jumble of school supplies, she found… a perfectly sharpened, ruby-encrusted pencil that seemed to hum with barely contained energy.  Confused, she shrugged it off.  Maybe Grandma had a hidden stash of fancy stationery.\n",
            "\n",
            "The next day, she needed her history textbook.  Instead of the textbook, she found a miniature, perfectly rendered model of the Roman Coliseum, complete with tiny, bustling figurines.  She could almost hear the roar of the crowd.  The following day, her missing gym shoes were replaced by shimmering, silver boots that seemed to float slightly above the ground.\n",
            "\n",
            "Word spread.  Whisperings about Elara and her “lucky” backpack started in the school hallways.  Some were jealous, others awestruck.  Elara, however, was terrified.  The backpack, it seemed, granted wishes, or at least, fulfilled needs in the most unexpected ways.  She needed a ride to soccer practice?  A miniature, perfectly functioning helicopter materialized from the depths of the bag.  Needed a quiet place to study? A secluded, sun-dappled glade appeared in her bedroom.\n",
            "\n",
            "The power of the backpack was both exhilarating and terrifying.  She tried to control it, to only ask for things she truly needed.  But the backpack seemed to have a mind of its own.  It anticipated her needs before she even knew them.  It felt like a benevolent, slightly chaotic genie.\n",
            "\n",
            "One day, her best friend, Liam, was heartbroken after a devastating loss.  Elara, remembering the solace she’d found in the miniature glade, reached into the backpack, hoping for something to comfort him.  Instead, she pulled out a small, wooden box. Inside, nestled on a bed of velvet, was a single, perfectly formed tear – a tear that shimmered with an ethereal light.  Liam, upon seeing the tear, felt a wave of unexpected peace wash over him.  It wasn’t a magical cure, but it was a tangible symbol of shared grief and a testament to the enduring power of friendship.\n",
            "\n",
            "Elara began to understand.  The backpack wasn't about material desires; it was about fulfilling deeper, emotional needs.  It was a conduit for empathy, offering comfort and solace in unexpected ways.  The backpack, it seemed, wasn't just magic; it was a mirror reflecting the unspoken needs of her heart, and the hearts of those around her.  And that, Elara realised, was a truly remarkable gift.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the prompt (\"Write a story about a magic backpack\") doesn't include any output examples, system instructions, or formatting information. It's a zero-shot approach. For some use cases, a one-shot or few-shot prompt might produce output that's more aligned with user expectations. In some cases, you might also want to provide system instructions to help the model understand the task or follow specific guidelines."
      ],
      "metadata": {
        "id": "xMyWazJRStWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate text from text-and-image input\n",
        "\n",
        "The Gemini API supports multimodal inputs that combine text with media files. The following example shows how to generate text from text-and-image input:"
      ],
      "metadata": {
        "id": "IVXLYHCiS52_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "organ = PIL.Image.open(\"/content/download.jpg\")\n",
        "response = model.generate_content([\"Tell me about this instrument\", organ])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "cde_zbJZS5bz",
        "outputId": "f410aa85-0320-450f-8fbf-987aa09a3927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's not an instrument; that's an illustration of major human organs.  The image shows:\n",
            "\n",
            "* **Brain:** The control center of the body.\n",
            "* **Kidneys:**  Filter waste from the blood.\n",
            "* **Heart:** Pumps blood throughout the body.\n",
            "* **Lungs:** Responsible for gas exchange (oxygen and carbon dioxide).\n",
            "* **Liver:**  Involved in many metabolic processes.\n",
            "* **Stomach:**  Digests food.\n",
            "\n",
            "\n",
            "It's a diagram used for educational purposes, likely to teach anatomy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate a text stream\n",
        "By default, the model returns a response after completing the entire text generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n",
        "\n",
        "The following example shows how to implement streaming using the streamGenerateContent method to generate text from a text-only input prompt."
      ],
      "metadata": {
        "id": "6rN7lWFKcj9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of programming and data processing, a \"chunk\" refers to a smaller, manageable piece of data that is part of a larger dataset or stream. The term is often used when working with large files, streams, or real-time data where handling the entire dataset at once would be inefficient or impractical.\n",
        "\n",
        "Meaning of \"Chunk\" in Different Contexts\n",
        "Data Streaming:\n",
        "\n",
        "In APIs that stream data (like the example in your code), a chunk is a segment of the response received from the server in real time.\n",
        "For example, when generating text, instead of waiting for the entire output, the AI sends back smaller portions of the text (chunks) as they are ready."
      ],
      "metadata": {
        "id": "P7ooLXOgdYeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "response = model.generate_content(\"Write a story about a magic backpack.\", stream=True)\n",
        "for chunk in response:\n",
        "    print(chunk.text)\n",
        "    print(\"_\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "2vMOZxEoVhL7",
        "outputId": "6465d025-2283-421a-de45-a9a1b638de40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El\n",
            "________________________________________________________________________________\n",
            "ara wasn't your average twelve-year-old.  While other kids\n",
            "________________________________________________________________________________\n",
            " dreamed of puppies and ponies, Elara dreamed of adventure.  Her dreams,\n",
            "________________________________________________________________________________\n",
            " however, were consistently thwarted by her painfully ordinary life in the sleepy town of Willow Creek. That is, until she found the backpack.\n",
            "\n",
            "It wasn't\n",
            "________________________________________________________________________________\n",
            " much to look at – faded canvas, scuffed leather straps, a single, tarnished brass buckle. She'd discovered it tucked away in her grandmother'\n",
            "________________________________________________________________________________\n",
            "s attic, nestled amongst dusty photo albums and forgotten toys.  Grandma Rose, her eyes twinkling with a mischievous glint, had simply said, \"It's a keeper, dearie.  Just… be careful what you wish for\n",
            "________________________________________________________________________________\n",
            ".\"\n",
            "\n",
            "That night, Elara, bored with her predictable homework, wished for a pet dragon.  The next morning, a tiny, emerald-scaled dragon, no bigger than her hand, perched on the backpack's strap, its\n",
            "________________________________________________________________________________\n",
            " miniature wings fluttering.  Sparky, as Elara named him, breathed puffs of harmless smoke and ate only the shiniest blueberries.\n",
            "\n",
            "The backpack's magic wasn't limited to dragons.  A wish for a map to the abandoned castle on Widow's Hill produced a perfectly detailed parchment, complete with secret\n",
            "________________________________________________________________________________\n",
            " passages marked in shimmering gold ink.  A wish for a picnic basket yielded a basket overflowing with the most delicious sandwiches, cakes, and fruit juices she'd ever tasted.  Even a wish for a solution to her algebra homework resulted in the correct answers appearing neatly written in her notebook.\n",
            "\n",
            "Elara's life\n",
            "________________________________________________________________________________\n",
            " transformed.  She explored hidden caves, befriended mischievous sprites, and even solved the mystery of the town's vanishing library books (turns out, it was a family of bookworm goblins!). Sparky, ever loyal, became her constant companion.\n",
            "\n",
            "But with each wish, a subtle change occurred. The backpack'\n",
            "________________________________________________________________________________\n",
            "s canvas became slightly more worn, the leather a shade darker.  Elara, initially thrilled, started to notice the creeping unease.  The magic, while amazing, felt… fleeting.  The wonders were becoming less vivid, less potent.\n",
            "\n",
            "One day, facing a difficult choice – to use the backpack'\n",
            "________________________________________________________________________________\n",
            "s magic to help her win a crucial science competition or to let her own efforts prevail – Elara realized the true nature of the magic. It wasn't about getting what she wanted; it was about learning to find her own strength.\n",
            "\n",
            "She chose to study, to work hard, to trust her own abilities.\n",
            "________________________________________________________________________________\n",
            " And, in doing so, she felt a surge of power far greater than any wish could grant.  When the science fair arrived, she presented her project, crafted with her own ingenuity and hard work, and won.\n",
            "\n",
            "That night, Elara looked at the backpack, now almost completely faded and worn. She gently\n",
            "________________________________________________________________________________\n",
            " placed it back in her grandmother's attic.  The magic was gone, but the adventures, the memories, and the newfound confidence remained, a richer treasure than any wish could ever provide.  She knew she'd always have Sparky, her tiny, blueberry-loving dragon, a testament to the incredible,\n",
            "________________________________________________________________________________\n",
            " if slightly imperfect, magic of the backpack.\n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build an interactive chat\n",
        "You can use the Gemini API to build interactive chat experiences for your users. Using the chat feature of the API lets you collect multiple rounds of questions and responses, allowing users to step incrementally toward answers or get help with multipart problems. This feature is ideal for applications that require ongoing communication, such as chatbots, interactive tutors, or customer support assistants.\n",
        "\n",
        "The following code example shows a basic chat implementation:"
      ],
      "metadata": {
        "id": "t9Y2h4UuW8fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "chat = model.start_chat(\n",
        "    history=[\n",
        "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
        "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
        "    ]\n",
        ")\n",
        "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
        "print(response.text)\n",
        "response = chat.send_message(\"How many paws are in my house?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "6q5AjQs9XB1B",
        "outputId": "8ce28512-5b23-4719-d8ba-a2054b9b2ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's wonderful!  Do you have any questions about them, or just wanted to share the good news?  Perhaps you'd like to tell me about them?  What breeds are they?\n",
            "\n",
            "If you have two dogs, and each dog has four paws, then there are eight paws in your house.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "myfile = genai.upload_file(media / \"sample.mp3\")\n",
        "print(f\"{myfile=}\")\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "result = model.generate_content([myfile, \"Describe this audio clip\"])\n",
        "print(f\"{result.text=}\")"
      ],
      "metadata": {
        "id": "8yw6Jow7fV5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "f2d5573b-254b-4741-93f8-39641ca25bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'media' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4b8243689d88>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerativeai\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedia\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"sample.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{myfile=}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'media' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/google-gemini/generative-ai-python@imagen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "eP_E-9H3tg-U",
        "outputId": "4327d722-e7a0-4b77-bb3c-4e59323afddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/google-gemini/generative-ai-python@imagen\n",
            "  Cloning https://github.com/google-gemini/generative-ai-python (to revision imagen) to /tmp/pip-req-build-mbd8w_bv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-gemini/generative-ai-python /tmp/pip-req-build-mbd8w_bv\n",
            "  Running command git checkout -b imagen --track origin/imagen\n",
            "  Switched to a new branch 'imagen'\n",
            "  Branch 'imagen' set up to track remote branch 'imagen' from 'origin'.\n",
            "  Resolved https://github.com/google-gemini/generative-ai-python to commit 2786f33edbabc441b247e549025b3e9e5e849895\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.25.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.2) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.2) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.2) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai==0.8.2) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.2) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (2024.8.30)\n",
            "Building wheels for collected packages: google-generativeai\n",
            "  Building wheel for google-generativeai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-generativeai: filename=google_generativeai-0.8.2-py3-none-any.whl size=161059 sha256=3fa7167760608cb39c692e94673b357ed4f007fad4a155705b667812246068b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-68a0vf_m/wheels/dc/8f/91/437bbb0d80260245a962e8cf6eaacbb34c4cbe50698c277acf\n",
            "Successfully built google-generativeai\n",
            "Installing collected packages: google-generativeai\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.8.3\n",
            "    Uninstalling google-generativeai-0.8.3:\n",
            "      Successfully uninstalled google-generativeai-0.8.3\n",
            "Successfully installed google-generativeai-0.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ab66d474910b48e7bc0cd783c765c51c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0T0cO1stqSI",
        "outputId": "42309292-3f9f-4df5-99b9-ba7793cd27ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key='AIzaSyAq9iAsOnsmcLfpiBHWjRyV34LHKboUWZ8')\n",
        "\n",
        "imagen = genai.ImageGenerationModel(\"imagen-3.0-generate-001\")\n",
        "\n",
        "result = imagen.generate_images(\n",
        "    prompt=\"Fuzzy bunnies in my kitchen\",\n",
        "    number_of_images=4,\n",
        "    safety_filter_level=\"block_only_high\",\n",
        "    person_generation=\"allow_adult\",\n",
        "    aspect_ratio=\"3:4\",\n",
        "    negative_prompt=\"Outside\",\n",
        ")\n",
        "\n",
        "for image in result.images:\n",
        "  print(image)\n",
        "\n",
        "# Open and display the image using your local operating system.\n",
        "for image in result.images:\n",
        "  image._pil_image.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "BXhlP7x1trlH",
        "outputId": "9ff9d6fc-282e-40f5-8f07-6e91830df313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'google.generativeai' has no attribute 'ImageGenerationModel'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-60f8a685d61b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AIzaSyAq9iAsOnsmcLfpiBHWjRyV34LHKboUWZ8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageGenerationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imagen-3.0-generate-001\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m result = imagen.generate_images(\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'google.generativeai' has no attribute 'ImageGenerationModel'"
          ]
        }
      ]
    }
  ]
}